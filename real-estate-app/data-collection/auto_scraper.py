#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∞ —Å–∏—Å—Ç–µ–º–∞ –ø–∞—Ä—Å–∏–Ω–≥—É –Ω–µ—Ä—É—Ö–æ–º–æ—Å—Ç—ñ –∑ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫–æ–º –∑–∞–≤–¥–∞–Ω—å
"""

import os
import sys
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import json
import requests
from apscheduler.schedulers.blocking import BlockingScheduler
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.events import EVENT_JOB_EXECUTED, EVENT_JOB_ERROR

# –î–æ–¥–∞—î–º–æ –∫–æ—Ä–µ–Ω–µ–≤—É –ø–∞–ø–∫—É –¥–æ —à–ª—è—Ö—É
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scrapers.olx_scraper import OLXScraper
from scrapers.domria_scraper import DomRiaScraper
from scrapers.realt_scraper import RealtScraper
from scrapers.address_scraper import AddressScraper
from models import PropertyListing, City, District
from database import DatabaseManager
from config import Config

class AutoScrapingManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É –∑ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫–æ–º"""

    def __init__(self):
        self.config = Config()
        self.db = DatabaseManager(self.config.DATABASE_URL)
        self.scheduler = BackgroundScheduler()

        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Å–∫—Ä–∞–ø–µ—Ä–∏ –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
        self.scrapers = {
            'olx': OLXScraper(),
            'dom_ria': DomRiaScraper(),
            'realt': RealtScraper(),
            'address': AddressScraper(),
        }

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
        self.stats = {
            'total_runs': 0,
            'successful_runs': 0,
            'failed_runs': 0,
            'total_listings_collected': 0,
            'last_run_time': None,
            'errors': []
        }

        self._setup_logging()
        self._setup_scrapers()

    def _setup_logging(self):
        """–ù–∞–ª–∞—à—Ç–æ–≤—É—î —Ä–æ–∑—à–∏—Ä–µ–Ω–µ –ª–æ–≥—É–≤–∞–Ω–Ω—è"""
        # –°—Ç–≤–æ—Ä—é—î–º–æ —Ñ–æ—Ä–º–∞—Ç–µ—Ä –¥–ª—è –ª–æ–≥—ñ–≤
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ —Ñ–∞–π–ª–æ–≤–∏–π –ª–æ–≥–µ—Ä –∑ —Ä–æ—Ç–∞—Ü—ñ—î—é
        from logging.handlers import RotatingFileHandler
        file_handler = RotatingFileHandler(
            self.config.LOG_FILE,
            maxBytes=self.config.LOG_MAX_SIZE,
            backupCount=self.config.LOG_BACKUP_COUNT
        )
        file_handler.setFormatter(formatter)

        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –∫–æ–Ω—Å–æ–ª—å–Ω–∏–π –ª–æ–≥–µ—Ä
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)

        # –ù–∞–ª–∞—à—Ç–æ–≤—É—î–º–æ –∫–æ—Ä–µ–Ω–µ–≤–∏–π –ª–æ–≥–µ—Ä
        logger = logging.getLogger()
        logger.setLevel(getattr(logging, self.config.LOG_LEVEL.upper()))
        logger.addHandler(file_handler)
        logger.addHandler(console_handler)

        self.logger = logging.getLogger(__name__)

    def _setup_scrapers(self):
        """–ù–∞–ª–∞—à—Ç–æ–≤—É—î —Å–∫—Ä–∞–ø–µ—Ä–∏ –∑ –∞–Ω—Ç–∏-–±–ª–æ–∫—É–≤–∞–ª—å–Ω–∏–º–∏ –∑–∞—Ö–æ–¥–∞–º–∏"""
        import random

        for scraper_name, scraper in self.scrapers.items():
            # –í–∏–±–∏—Ä–∞—î–º–æ –≤–∏–ø–∞–¥–∫–æ–≤–∏–π User-Agent
            random_ua = random.choice(self.config.USER_AGENTS_POOL)
            scraper.session.headers.update({
                'User-Agent': random_ua,
                'Accept-Language': 'uk-UA,uk;q=0.9,en;q=0.8',
                'Referer': 'https://www.google.com/',
            })

            self.logger.info(f"–ù–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ {scraper_name} –∑ User-Agent: {random_ua[:50]}...")

    def collect_data_from_source(self, source: str, cities: List[str]) -> Dict[str, List[Dict]]:
        """–ó–±–∏—Ä–∞—î –¥–∞–Ω—ñ –∑ –æ–¥–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ –¥–ª—è –≤—Å—ñ—Ö –º—ñ—Å—Ç"""
        if source not in self.scrapers:
            self.logger.error(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π –¥–∂–µ—Ä–µ–ª–æ: {source}")
            return {}

        scraper = self.scrapers[source]
        self.logger.info(f"–ü–æ—á–∏–Ω–∞—é –∑–±—ñ—Ä –¥–∞–Ω–∏—Ö –∑ {source} –¥–ª—è –º—ñ—Å—Ç: {cities}")

        try:
            # –ó–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –∑ –æ–¥–Ω–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞ –¥–ª—è –≤—Å—ñ—Ö –º—ñ—Å—Ç
            source_data = scraper.scrape_multiple_cities(
                cities,
                self.config.MAX_PAGES_PER_CITY
            )

            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –¥–∞–Ω—ñ –≤ –±–∞–∑—É
            self._save_listings_to_db(source_data, source)

            listings_count = sum(len(listings) for listings in source_data.values())
            self.logger.info(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∑–±—ñ—Ä –∑ {source}: {listings_count} –æ–≥–æ–ª–æ—à–µ–Ω—å")

            return source_data

        except Exception as e:
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–æ—Ä—ñ –∑ {source}: {e}")
            self.stats['errors'].append({
                'source': source,
                'error': str(e),
                'timestamp': datetime.utcnow().isoformat()
            })
            return {}

    def _save_listings_to_db(self, source_data: Dict[str, List[Dict]], source: str):
        """–ó–±–µ—Ä—ñ–≥–∞—î –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö –∑ –¥–µ–¥—É–ø–ª—ñ–∫–∞—Ü—ñ—î—é"""
        with self.db.get_session() as session:
            for city_name, listings in source_data.items():
                self.logger.info(f"–ó–±–µ—Ä—ñ–≥–∞—é {len(listings)} –æ–≥–æ–ª–æ—à–µ–Ω—å –¥–ª—è {city_name}")

                for listing_data in listings:
                    try:
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∞–±–æ –æ–Ω–æ–≤–ª—é—î–º–æ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è
                        listing = session.query(PropertyListing).filter_by(
                            external_id=listing_data['external_id'],
                            source=source
                        ).first()

                        if listing:
                            # –û–Ω–æ–≤–ª—é—î–º–æ —ñ—Å–Ω—É—é—á–µ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è
                            for key, value in listing_data.items():
                                if hasattr(listing, key):
                                    setattr(listing, key, value)
                            listing.last_seen_at = datetime.utcnow()
                        else:
                            # –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–µ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è
                            listing = PropertyListing(**listing_data)
                            session.add(listing)

                    except Exception as e:
                        self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ –æ–≥–æ–ª–æ—à–µ–Ω–Ω—è {listing_data.get('external_id')}: {e}")

            session.commit()

    def run_full_scraping_cycle(self):
        """–ó–∞–ø—É—Å–∫–∞—î –ø–æ–≤–Ω–∏–π —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥—É –≤—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª"""
        self.logger.info("=" * 50)
        self.logger.info(f"–ü–û–ß–ò–ù–ê–Æ –ê–í–¢–û–ú–ê–¢–ò–ß–ù–ò–ô –¶–ò–ö–õ –ü–ê–†–°–ò–ù–ì–£ #{self.stats['total_runs'] + 1}")
        self.logger.info("=" * 50)

        start_time = time.time()
        self.stats['total_runs'] += 1

        try:
            all_data = {}

            # –ü—Ä–æ—Ö–æ–¥–∏–º–æ –ø–æ –≤—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª–∞—Ö
            for source in self.config.SOURCES:
                source_data = self.collect_data_from_source(source, self.config.CITIES)
                all_data[source] = source_data

                # –ü–∞—É–∑–∞ –º—ñ–∂ –¥–∂–µ—Ä–µ–ª–∞–º–∏
                time.sleep(5)

            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_listings = sum(
                sum(len(listings) for listings in city_listings.values())
                for city_listings in all_data.values()
            )

            self.stats['total_listings_collected'] += total_listings
            self.stats['successful_runs'] += 1
            self.stats['last_run_time'] = datetime.utcnow()

            # –û—á–∏—â–∞—î–º–æ —Å—Ç–∞—Ä—ñ –ø–æ–º–∏–ª–∫–∏ (–∑–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ 10)
            if len(self.stats['errors']) > 10:
                self.stats['errors'] = self.stats['errors'][-10:]

            execution_time = time.time() - start_time

            self.logger.info("=" * 50)
            self.logger.info(f"–¶–ò–ö–õ –ü–ê–†–°–ò–ù–ì–£ –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–Ü–®–ù–û")
            self.logger.info(f"–ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {execution_time:.2f} —Å–µ–∫—É–Ω–¥")
            self.logger.info(f"–ó—ñ–±—Ä–∞–Ω–æ –æ–≥–æ–ª–æ—à–µ–Ω—å: {total_listings}")
            self.logger.info(f"–ó–∞–≥–∞–ª–æ–º –∑–∞ –≤—Å—ñ —Ü–∏–∫–ª–∏: {self.stats['total_listings_collected']}")
            self.logger.info("=" * 50)

            # –ù–∞–¥—Å–∏–ª–∞—î–º–æ —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è –≤ Telegram (—è–∫—â–æ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ)
            self._send_telegram_notification(total_listings, execution_time)

        except Exception as e:
            self.stats['failed_runs'] += 1
            self.logger.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ –≤ —Ü–∏–∫–ª—ñ –ø–∞—Ä—Å–∏–Ω–≥—É: {e}")
            self.stats['errors'].append({
                'error': str(e),
                'timestamp': datetime.utcnow().isoformat()
            })

    def _send_telegram_notification(self, listings_count: int, execution_time: float):
        """–ù–∞–¥—Å–∏–ª–∞—î —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è –≤ Telegram –ø—Ä–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–∞—Ä—Å–∏–Ω–≥—É"""
        if not (self.config.TELEGRAM_BOT_TOKEN and self.config.TELEGRAM_CHAT_ID):
            return

        try:
            message = f"""
ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ

üìä –†–µ–∑—É–ª—å—Ç–∞—Ç–∏:
‚Ä¢ –ó—ñ–±—Ä–∞–Ω–æ –æ–≥–æ–ª–æ—à–µ–Ω—å: {listings_count}
‚Ä¢ –ß–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {execution_time:.2f}—Å
‚Ä¢ –¶–∏–∫–ª: #{self.stats['total_runs']}
‚Ä¢ –ó–∞–≥–∞–ª–æ–º –∑–∞ –≤—Å—ñ —Ü–∏–∫–ª–∏: {self.stats['total_listings_collected']}

‚è∞ –ù–∞—Å—Ç—É–ø–Ω–∏–π —Ü–∏–∫–ª —á–µ—Ä–µ–∑ {self.config.SCRAPING_INTERVAL_HOURS} –≥–æ–¥–∏–Ω—É
            """.strip()

            url = f"https://api.telegram.org/bot{self.config.TELEGRAM_BOT_TOKEN}/sendMessage"
            data = {
                'chat_id': self.config.TELEGRAM_CHAT_ID,
                'text': message,
                'parse_mode': 'HTML'
            }

            response = requests.post(url, data=data, timeout=10)
            if response.status_code == 200:
                self.logger.info("–°–ø–æ–≤—ñ—â–µ–Ω–Ω—è –Ω–∞–¥—ñ—Å–ª–∞–Ω–æ –≤ Telegram")
            else:
                self.logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –Ω–∞–¥—Å–∏–ª–∞–Ω–Ω—è –≤ Telegram: {response.status_code}")

        except Exception as e:
            self.logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ —Å–ø–æ–≤—ñ—â–µ–Ω–Ω—è –≤ Telegram: {e}")

    def get_status_report(self) -> Dict[str, Any]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î –∑–≤—ñ—Ç –ø—Ä–æ —Å—Ç–∞–Ω —Å–∏—Å—Ç–µ–º–∏"""
        uptime = None
        if self.stats['last_run_time']:
            uptime = datetime.utcnow() - self.stats['last_run_time']

        return {
            'system_status': 'running',
            'total_runs': self.stats['total_runs'],
            'successful_runs': self.stats['successful_runs'],
            'failed_runs': self.stats['failed_runs'],
            'success_rate': (self.stats['successful_runs'] / max(1, self.stats['total_runs'])) * 100,
            'total_listings_collected': self.stats['total_listings_collected'],
            'last_run_time': self.stats['last_run_time'].isoformat() if self.stats['last_run_time'] else None,
            'uptime_seconds': uptime.total_seconds() if uptime else None,
            'recent_errors': self.stats['errors'][-5:],  # –û—Å—Ç–∞–Ω–Ω—ñ 5 –ø–æ–º–∏–ª–æ–∫
            'next_run_in': self._get_next_run_time(),
        }

    def _get_next_run_time(self) -> Optional[str]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î —á–∞—Å –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫—É"""
        try:
            # –û—Ç—Ä–∏–º—É—î–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π –∑–∞–ø–ª–∞–Ω–æ–≤–∞–Ω–∏–π –∑–∞–ø—É—Å–∫
            job = self.scheduler.get_job('scraping_cycle')
            if job and job.next_run_time:
                return job.next_run_time.isoformat()
        except:
            pass
        return None

    def start_scheduler(self):
        """–ó–∞–ø—É—Å–∫–∞—î –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –∑–∞–≤–¥–∞–Ω—å"""
        self.logger.info("–ó–∞–ø—É—Å–∫–∞—é –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥—É...")

        # –ü–ª–∞–Ω—É—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –ø–∞—Ä—Å–∏–Ω–≥—É
        trigger = IntervalTrigger(hours=self.config.SCRAPING_INTERVAL_HOURS)

        self.scheduler.add_job(
            func=self.run_full_scraping_cycle,
            trigger=trigger,
            id='scraping_cycle',
            name='Full Scraping Cycle',
            replace_existing=True
        )

        # –î–æ–¥–∞—î–º–æ –æ–±—Ä–æ–±–Ω–∏–∫–∏ –ø–æ–¥—ñ–π –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
        def job_executed_listener(event):
            self.logger.info(f"–ó–∞–≤–¥–∞–Ω–Ω—è {event.job_id} –≤–∏–∫–æ–Ω–∞–Ω–æ —É—Å–ø—ñ—à–Ω–æ")

        def job_error_listener(event):
            self.logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤ –∑–∞–≤–¥–∞–Ω–Ω—ñ {event.job_id}: {event.exception}")

        self.scheduler.add_listener(job_executed_listener, EVENT_JOB_EXECUTED)
        self.scheduler.add_listener(job_error_listener, EVENT_JOB_ERROR)

        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫
        self.scheduler.start()
        self.logger.info(f"–ü–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –∑–∞–ø—É—â–µ–Ω–æ. –ù–∞—Å—Ç—É–ø–Ω–∏–π —Ü–∏–∫–ª —á–µ—Ä–µ–∑ {self.config.SCRAPING_INTERVAL_HOURS} –≥–æ–¥–∏–Ω—É")

        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π —Ü–∏–∫–ª –Ω–µ–≥–∞–π–Ω–æ (–¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)
        # self.run_full_scraping_cycle()

    def stop_scheduler(self):
        """–ó—É–ø–∏–Ω—è—î –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫"""
        self.logger.info("–ó—É–ø–∏–Ω—è—é –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫...")
        self.scheduler.shutdown()
        self.logger.info("–ü–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫ –∑—É–ø–∏–Ω–µ–Ω–æ")

    def run_once(self):
        """–ó–∞–ø—É—Å–∫–∞—î –æ–¥–∏–Ω —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥—É (–¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)"""
        self.run_full_scraping_cycle()


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    manager = AutoScrapingManager()

    if len(sys.argv) > 1 and sys.argv[1] == '--once':
        # –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª—É (–¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è)
        manager.run_once()
    else:
        # –ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫–∞
        try:
            manager.start_scheduler()

            # –ë–µ–∑–∫—ñ–Ω–µ—á–Ω–∏–π —Ü–∏–∫–ª –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ä–æ–±–æ—Ç–∏ –ø–ª–∞–Ω—É–≤–∞–ª—å–Ω–∏–∫–∞
            while True:
                time.sleep(60)  # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–∂–Ω—É —Ö–≤–∏–ª–∏–Ω—É

                # –õ–æ–≥—É—î–º–æ —Å—Ç–∞—Ç—É—Å –∫–æ–∂–Ω—É –≥–æ–¥–∏–Ω—É
                if int(time.time()) % 3600 < 60:
                    status = manager.get_status_report()
                    manager.logger.info(f"–°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º–∏: {status}")

        except KeyboardInterrupt:
            manager.logger.info("–û—Ç—Ä–∏–º–∞–Ω–æ —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è")
        finally:
            manager.stop_scheduler()


if __name__ == "__main__":
    main()
